{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "edb9178a-fd4f-4ee0-87d6-351aa616b4de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import TestResults,TrainSplit\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import f1_score, log_loss\n",
    "\n",
    "import numpy as np\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "132281bb-153a-4220-bacf-63f42ecb63b3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the data\n",
      "Categorial Feature Imputed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "NUM IMPUTE: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11/11 [00:00<00:00, 47.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spliting the Data based on time\n",
      "X_train:(3387880, 80), X_test:(97972, 80) , y_train:(3387880, 2) , y_test:(97972, 2)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = TrainSplit().get_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ddcb0790-a17f-4e73-8a65-f608f272734c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_feat = TrainSplit.CATEGORIES + TrainSplit.BINARY\n",
    "num_feat = TrainSplit.NUMERICAL\n",
    "all_feat = cat_feat + num_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb98060a-33cd-4b6d-bdda-bc0766aab64f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "X = pd.concat([X_train,X_test],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e401f6e-d242-41e8-82de-4cfc50b52615",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f_2</th>\n",
       "      <th>f_3</th>\n",
       "      <th>f_4</th>\n",
       "      <th>f_5</th>\n",
       "      <th>f_6</th>\n",
       "      <th>f_7</th>\n",
       "      <th>f_8</th>\n",
       "      <th>f_9</th>\n",
       "      <th>f_10</th>\n",
       "      <th>f_11</th>\n",
       "      <th>...</th>\n",
       "      <th>f_70</th>\n",
       "      <th>f_71</th>\n",
       "      <th>f_72</th>\n",
       "      <th>f_73</th>\n",
       "      <th>f_74</th>\n",
       "      <th>f_75</th>\n",
       "      <th>f_76</th>\n",
       "      <th>f_77</th>\n",
       "      <th>f_78</th>\n",
       "      <th>f_79</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30131</td>\n",
       "      <td>7152</td>\n",
       "      <td>16170</td>\n",
       "      <td>25604</td>\n",
       "      <td>25613</td>\n",
       "      <td>27941</td>\n",
       "      <td>21218</td>\n",
       "      <td>869</td>\n",
       "      <td>22970</td>\n",
       "      <td>11810</td>\n",
       "      <td>...</td>\n",
       "      <td>0.672952</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.426729</td>\n",
       "      <td>0.571121</td>\n",
       "      <td>0.115692</td>\n",
       "      <td>1.156922</td>\n",
       "      <td>0.269948</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20095</td>\n",
       "      <td>563</td>\n",
       "      <td>22861</td>\n",
       "      <td>25604</td>\n",
       "      <td>22651</td>\n",
       "      <td>27941</td>\n",
       "      <td>19203</td>\n",
       "      <td>869</td>\n",
       "      <td>19343</td>\n",
       "      <td>28763</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.571121</td>\n",
       "      <td>0.571121</td>\n",
       "      <td>0.115692</td>\n",
       "      <td>1.156922</td>\n",
       "      <td>0.269948</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20095</td>\n",
       "      <td>563</td>\n",
       "      <td>22861</td>\n",
       "      <td>25604</td>\n",
       "      <td>21280</td>\n",
       "      <td>27941</td>\n",
       "      <td>21621</td>\n",
       "      <td>23218</td>\n",
       "      <td>22970</td>\n",
       "      <td>12213</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000305</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.156922</td>\n",
       "      <td>0.038564</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17758</td>\n",
       "      <td>22294</td>\n",
       "      <td>29040</td>\n",
       "      <td>25604</td>\n",
       "      <td>15836</td>\n",
       "      <td>27941</td>\n",
       "      <td>21218</td>\n",
       "      <td>21533</td>\n",
       "      <td>22970</td>\n",
       "      <td>28360</td>\n",
       "      <td>...</td>\n",
       "      <td>1.046330</td>\n",
       "      <td>0.571121</td>\n",
       "      <td>5.711215</td>\n",
       "      <td>2.284486</td>\n",
       "      <td>0.115692</td>\n",
       "      <td>1.156922</td>\n",
       "      <td>0.269948</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11077</td>\n",
       "      <td>7152</td>\n",
       "      <td>18575</td>\n",
       "      <td>15908</td>\n",
       "      <td>16861</td>\n",
       "      <td>27941</td>\n",
       "      <td>21218</td>\n",
       "      <td>9638</td>\n",
       "      <td>19343</td>\n",
       "      <td>11407</td>\n",
       "      <td>...</td>\n",
       "      <td>0.658138</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.142243</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.038564</td>\n",
       "      <td>1.156922</td>\n",
       "      <td>0.269948</td>\n",
       "      <td>0.0</td>\n",
       "      <td>37.384575</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3485578</th>\n",
       "      <td>20095</td>\n",
       "      <td>563</td>\n",
       "      <td>31686</td>\n",
       "      <td>21545</td>\n",
       "      <td>590</td>\n",
       "      <td>27941</td>\n",
       "      <td>19203</td>\n",
       "      <td>6675</td>\n",
       "      <td>22970</td>\n",
       "      <td>30251</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000204</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.571121</td>\n",
       "      <td>0.571121</td>\n",
       "      <td>0.038564</td>\n",
       "      <td>1.156922</td>\n",
       "      <td>0.077128</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3485664</th>\n",
       "      <td>11077</td>\n",
       "      <td>7152</td>\n",
       "      <td>18575</td>\n",
       "      <td>21545</td>\n",
       "      <td>32377</td>\n",
       "      <td>27941</td>\n",
       "      <td>21218</td>\n",
       "      <td>6675</td>\n",
       "      <td>19343</td>\n",
       "      <td>11810</td>\n",
       "      <td>...</td>\n",
       "      <td>0.750122</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.571121</td>\n",
       "      <td>0.571121</td>\n",
       "      <td>0.115692</td>\n",
       "      <td>1.156922</td>\n",
       "      <td>0.269948</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3485724</th>\n",
       "      <td>20095</td>\n",
       "      <td>563</td>\n",
       "      <td>31686</td>\n",
       "      <td>21545</td>\n",
       "      <td>590</td>\n",
       "      <td>27941</td>\n",
       "      <td>18800</td>\n",
       "      <td>6675</td>\n",
       "      <td>22970</td>\n",
       "      <td>29166</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000204</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.142243</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.115692</td>\n",
       "      <td>1.156922</td>\n",
       "      <td>0.269948</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3485743</th>\n",
       "      <td>26325</td>\n",
       "      <td>7779</td>\n",
       "      <td>21563</td>\n",
       "      <td>25604</td>\n",
       "      <td>29287</td>\n",
       "      <td>27941</td>\n",
       "      <td>21218</td>\n",
       "      <td>14659</td>\n",
       "      <td>19343</td>\n",
       "      <td>31181</td>\n",
       "      <td>...</td>\n",
       "      <td>2.177379</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.115692</td>\n",
       "      <td>1.156922</td>\n",
       "      <td>0.269948</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3485807</th>\n",
       "      <td>15471</td>\n",
       "      <td>22294</td>\n",
       "      <td>6213</td>\n",
       "      <td>21545</td>\n",
       "      <td>8595</td>\n",
       "      <td>27941</td>\n",
       "      <td>21218</td>\n",
       "      <td>6675</td>\n",
       "      <td>19343</td>\n",
       "      <td>11407</td>\n",
       "      <td>...</td>\n",
       "      <td>2.665035</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.115692</td>\n",
       "      <td>1.156922</td>\n",
       "      <td>0.269948</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3485852 rows × 78 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           f_2    f_3    f_4    f_5    f_6    f_7    f_8    f_9   f_10   f_11  \\\n",
       "0        30131   7152  16170  25604  25613  27941  21218    869  22970  11810   \n",
       "1        20095    563  22861  25604  22651  27941  19203    869  19343  28763   \n",
       "2        20095    563  22861  25604  21280  27941  21621  23218  22970  12213   \n",
       "3        17758  22294  29040  25604  15836  27941  21218  21533  22970  28360   \n",
       "4        11077   7152  18575  15908  16861  27941  21218   9638  19343  11407   \n",
       "...        ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "3485578  20095    563  31686  21545    590  27941  19203   6675  22970  30251   \n",
       "3485664  11077   7152  18575  21545  32377  27941  21218   6675  19343  11810   \n",
       "3485724  20095    563  31686  21545    590  27941  18800   6675  22970  29166   \n",
       "3485743  26325   7779  21563  25604  29287  27941  21218  14659  19343  31181   \n",
       "3485807  15471  22294   6213  21545   8595  27941  21218   6675  19343  11407   \n",
       "\n",
       "         ...      f_70      f_71      f_72      f_73      f_74      f_75  \\\n",
       "0        ...  0.672952  0.000000  3.426729  0.571121  0.115692  1.156922   \n",
       "1        ...  0.000000  0.000000  0.571121  0.571121  0.115692  1.156922   \n",
       "2        ...  0.000305  0.000000  0.000000  0.000000  0.000000  1.156922   \n",
       "3        ...  1.046330  0.571121  5.711215  2.284486  0.115692  1.156922   \n",
       "4        ...  0.658138  0.000000  1.142243  0.000000  0.038564  1.156922   \n",
       "...      ...       ...       ...       ...       ...       ...       ...   \n",
       "3485578  ...  0.000204  0.000000  0.571121  0.571121  0.038564  1.156922   \n",
       "3485664  ...  0.750122  0.000000  0.571121  0.571121  0.115692  1.156922   \n",
       "3485724  ...  0.000204  0.000000  1.142243  0.000000  0.115692  1.156922   \n",
       "3485743  ...  2.177379  0.000000  0.000000  0.000000  0.115692  1.156922   \n",
       "3485807  ...  2.665035  0.000000  0.000000  0.000000  0.115692  1.156922   \n",
       "\n",
       "             f_76  f_77       f_78  f_79  \n",
       "0        0.269948   0.0   0.000000   0.0  \n",
       "1        0.269948   0.0   0.000000   0.0  \n",
       "2        0.038564   0.0   0.000000   0.0  \n",
       "3        0.269948   0.0   0.000000   0.0  \n",
       "4        0.269948   0.0  37.384575   0.0  \n",
       "...           ...   ...        ...   ...  \n",
       "3485578  0.077128   0.0   0.000000   0.0  \n",
       "3485664  0.269948   0.0   0.000000   0.0  \n",
       "3485724  0.269948   0.0   0.000000   0.0  \n",
       "3485743  0.269948   0.0   0.000000   0.0  \n",
       "3485807  0.269948   0.0   0.000000   0.0  \n",
       "\n",
       "[3485852 rows x 78 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[all_feat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5315406d-5f8f-420d-9ec5-dee75d17c50a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pd.concat([y_train,y_test],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e31a977d-1afc-400a-852f-fa189ba64593",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trail):\n",
    "    params = {\n",
    "        'max_depth':trail.suggest_int('max_depth',3,8),\n",
    "        'learning_rate':trail.suggest_float('learning_rate',0.05,0.3),\n",
    "        'n_estimators':trail.suggest_int('n_estimators',100,650),\n",
    "        'tree_method':'gpu_hist',\n",
    "        'objective':'binary:logistic'\n",
    "    }\n",
    "    target = TrainSplit.IS_INSTALLED[0]\n",
    "    model = XGBClassifier(**params)\n",
    "    model.fit(X_train[use_features],y_train[target])\n",
    "    y_pred = model.predict(X_test[use_features])\n",
    "    score = log_loss(y_test[target],y_pred)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "26c01192-d70f-400b-8370-e0a457b19cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_click = {'max_depth': 4, 'learning_rate': 0.08751617649545007, 'n_estimators': 549}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1bc79e7a-6a71-4aa4-b83c-22f5817d3478",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-24 03:32:45,567]\u001b[0m A new study created in memory with name: install_log_loss\u001b[0m\n",
      "\u001b[32m[I 2023-05-24 03:32:53,883]\u001b[0m Trial 0 finished with value: 6.3915016938015645 and parameters: {'max_depth': 3, 'learning_rate': 0.08271949323619097, 'n_estimators': 304}. Best is trial 0 with value: 6.3915016938015645.\u001b[0m\n",
      "\u001b[32m[I 2023-05-24 03:33:02,464]\u001b[0m Trial 1 finished with value: 6.3188824055966135 and parameters: {'max_depth': 3, 'learning_rate': 0.1624819641702333, 'n_estimators': 407}. Best is trial 1 with value: 6.3188824055966135.\u001b[0m\n",
      "\u001b[32m[I 2023-05-24 03:33:11,412]\u001b[0m Trial 2 finished with value: 6.305488341793212 and parameters: {'max_depth': 5, 'learning_rate': 0.11920574126675722, 'n_estimators': 309}. Best is trial 2 with value: 6.305488341793212.\u001b[0m\n",
      "\u001b[32m[I 2023-05-24 03:33:20,143]\u001b[0m Trial 3 finished with value: 6.271646099116423 and parameters: {'max_depth': 5, 'learning_rate': 0.15740168923044817, 'n_estimators': 301}. Best is trial 3 with value: 6.271646099116423.\u001b[0m\n",
      "\u001b[32m[I 2023-05-24 03:33:29,371]\u001b[0m Trial 4 finished with value: 6.261422046406431 and parameters: {'max_depth': 7, 'learning_rate': 0.09854054258261537, 'n_estimators': 245}. Best is trial 4 with value: 6.261422046406431.\u001b[0m\n",
      "\u001b[32m[I 2023-05-24 03:33:37,840]\u001b[0m Trial 5 finished with value: 6.28716038922524 and parameters: {'max_depth': 6, 'learning_rate': 0.1864105689593044, 'n_estimators': 239}. Best is trial 4 with value: 6.261422046406431.\u001b[0m\n",
      "\u001b[32m[I 2023-05-24 03:33:44,991]\u001b[0m Trial 6 finished with value: 6.284689894595107 and parameters: {'max_depth': 4, 'learning_rate': 0.26612849343468725, 'n_estimators': 240}. Best is trial 4 with value: 6.261422046406431.\u001b[0m\n",
      "\u001b[32m[I 2023-05-24 03:33:50,855]\u001b[0m Trial 7 finished with value: 6.407020888965451 and parameters: {'max_depth': 5, 'learning_rate': 0.19021715692416824, 'n_estimators': 130}. Best is trial 4 with value: 6.261422046406431.\u001b[0m\n",
      "\u001b[32m[I 2023-05-24 03:33:57,185]\u001b[0m Trial 8 finished with value: 6.307959350597172 and parameters: {'max_depth': 6, 'learning_rate': 0.25819614723335294, 'n_estimators': 135}. Best is trial 4 with value: 6.261422046406431.\u001b[0m\n",
      "\u001b[32m[I 2023-05-24 03:34:02,123]\u001b[0m Trial 9 finished with value: 6.466590431966018 and parameters: {'max_depth': 3, 'learning_rate': 0.09043897121935064, 'n_estimators': 113}. Best is trial 4 with value: 6.261422046406431.\u001b[0m\n",
      "\u001b[32m[I 2023-05-24 03:34:21,988]\u001b[0m Trial 10 finished with value: 6.306551748106855 and parameters: {'max_depth': 8, 'learning_rate': 0.06125966949206866, 'n_estimators': 568}. Best is trial 4 with value: 6.261422046406431.\u001b[0m\n",
      "\u001b[32m[I 2023-05-24 03:34:37,590]\u001b[0m Trial 11 finished with value: 6.407381163276059 and parameters: {'max_depth': 8, 'learning_rate': 0.1342849863961938, 'n_estimators': 426}. Best is trial 4 with value: 6.261422046406431.\u001b[0m\n",
      "\u001b[32m[I 2023-05-24 03:34:53,664]\u001b[0m Trial 12 finished with value: 6.2906836231024945 and parameters: {'max_depth': 7, 'learning_rate': 0.0562013542608705, 'n_estimators': 488}. Best is trial 4 with value: 6.261422046406431.\u001b[0m\n",
      "\u001b[32m[I 2023-05-24 03:35:04,318]\u001b[0m Trial 13 finished with value: 6.390103281148202 and parameters: {'max_depth': 7, 'learning_rate': 0.12378560145065758, 'n_estimators': 285}. Best is trial 4 with value: 6.261422046406431.\u001b[0m\n",
      "\u001b[32m[I 2023-05-24 03:35:23,829]\u001b[0m Trial 14 finished with value: 6.409144820587011 and parameters: {'max_depth': 7, 'learning_rate': 0.1542421385024682, 'n_estimators': 637}. Best is trial 4 with value: 6.261422046406431.\u001b[0m\n",
      "\u001b[32m[I 2023-05-24 03:35:31,355]\u001b[0m Trial 15 finished with value: 6.248730869761388 and parameters: {'max_depth': 5, 'learning_rate': 0.21726747146652647, 'n_estimators': 218}. Best is trial 15 with value: 6.248730869761388.\u001b[0m\n",
      "\u001b[32m[I 2023-05-24 03:35:39,045]\u001b[0m Trial 16 finished with value: 6.27376350154654 and parameters: {'max_depth': 6, 'learning_rate': 0.2187020063054348, 'n_estimators': 206}. Best is trial 15 with value: 6.248730869761388.\u001b[0m\n",
      "\u001b[32m[I 2023-05-24 03:35:45,430]\u001b[0m Trial 17 finished with value: 6.306896009575445 and parameters: {'max_depth': 4, 'learning_rate': 0.22852667294921652, 'n_estimators': 184}. Best is trial 15 with value: 6.248730869761388.\u001b[0m\n",
      "\u001b[32m[I 2023-05-24 03:35:54,438]\u001b[0m Trial 18 finished with value: 6.269179407740307 and parameters: {'max_depth': 4, 'learning_rate': 0.2871432301519985, 'n_estimators': 350}. Best is trial 15 with value: 6.248730869761388.\u001b[0m\n",
      "\u001b[32m[I 2023-05-24 03:36:02,960]\u001b[0m Trial 19 finished with value: 6.3277034752192325 and parameters: {'max_depth': 7, 'learning_rate': 0.2043426610018504, 'n_estimators': 207}. Best is trial 15 with value: 6.248730869761388.\u001b[0m\n",
      "\u001b[32m[I 2023-05-24 03:36:17,235]\u001b[0m Trial 20 finished with value: 6.386229591231975 and parameters: {'max_depth': 8, 'learning_rate': 0.17486995763902669, 'n_estimators': 380}. Best is trial 15 with value: 6.248730869761388.\u001b[0m\n",
      "\u001b[32m[I 2023-05-24 03:36:26,510]\u001b[0m Trial 21 finished with value: 6.259660633505037 and parameters: {'max_depth': 4, 'learning_rate': 0.29458400724031797, 'n_estimators': 354}. Best is trial 15 with value: 6.248730869761388.\u001b[0m\n",
      "\u001b[32m[I 2023-05-24 03:36:33,992]\u001b[0m Trial 22 finished with value: 6.248026244205809 and parameters: {'max_depth': 4, 'learning_rate': 0.2972844912008205, 'n_estimators': 257}. Best is trial 22 with value: 6.248026244205809.\u001b[0m\n",
      "\u001b[32m[I 2023-05-24 03:36:45,001]\u001b[0m Trial 23 finished with value: 6.271295969537024 and parameters: {'max_depth': 4, 'learning_rate': 0.29577496723764257, 'n_estimators': 458}. Best is trial 22 with value: 6.248026244205809.\u001b[0m\n",
      "\u001b[32m[I 2023-05-24 03:36:51,584]\u001b[0m Trial 24 finished with value: 6.321354679431415 and parameters: {'max_depth': 5, 'learning_rate': 0.2568913903782716, 'n_estimators': 164}. Best is trial 22 with value: 6.248026244205809.\u001b[0m\n",
      "\u001b[32m[I 2023-05-24 03:37:00,517]\u001b[0m Trial 25 finished with value: 6.2667116961780245 and parameters: {'max_depth': 4, 'learning_rate': 0.2959654256521102, 'n_estimators': 350}. Best is trial 22 with value: 6.248026244205809.\u001b[0m\n",
      "\u001b[32m[I 2023-05-24 03:37:12,243]\u001b[0m Trial 26 finished with value: 6.272000244148561 and parameters: {'max_depth': 4, 'learning_rate': 0.2767373605440104, 'n_estimators': 501}. Best is trial 22 with value: 6.248026244205809.\u001b[0m\n",
      "\u001b[32m[I 2023-05-24 03:37:20,820]\u001b[0m Trial 27 finished with value: 6.295268761579358 and parameters: {'max_depth': 5, 'learning_rate': 0.23870683470590354, 'n_estimators': 274}. Best is trial 22 with value: 6.248026244205809.\u001b[0m\n",
      "\u001b[32m[I 2023-05-24 03:37:28,850]\u001b[0m Trial 28 finished with value: 6.299847166827549 and parameters: {'max_depth': 3, 'learning_rate': 0.24762925679019487, 'n_estimators': 359}. Best is trial 22 with value: 6.248026244205809.\u001b[0m\n",
      "\u001b[32m[I 2023-05-24 03:37:36,588]\u001b[0m Trial 29 finished with value: 6.297026273288865 and parameters: {'max_depth': 3, 'learning_rate': 0.27568119321478973, 'n_estimators': 338}. Best is trial 22 with value: 6.248026244205809.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "use_features = cat_feat\n",
    "study_install = optuna.create_study(direction='minimize',study_name='install_log_loss')\n",
    "study_install.optimize(objective, n_trials=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bf25fcfa-43c8-4fab-8c2b-cdc0155cfb4b",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-24 03:40:53,185]\u001b[0m A new study created in memory with name: install_log_loss\u001b[0m\n",
      "\u001b[32m[I 2023-05-24 03:41:03,844]\u001b[0m Trial 0 finished with value: 6.315358649384043 and parameters: {'max_depth': 8, 'learning_rate': 0.28174304603908057, 'n_estimators': 340}. Best is trial 0 with value: 6.315358649384043.\u001b[0m\n",
      "\u001b[32m[I 2023-05-24 03:41:10,920]\u001b[0m Trial 1 finished with value: 6.270233575248056 and parameters: {'max_depth': 6, 'learning_rate': 0.17188265984298395, 'n_estimators': 237}. Best is trial 1 with value: 6.270233575248056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-24 03:41:15,117]\u001b[0m Trial 2 finished with value: 6.287506152407862 and parameters: {'max_depth': 6, 'learning_rate': 0.25719682871806077, 'n_estimators': 101}. Best is trial 1 with value: 6.270233575248056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-24 03:41:27,760]\u001b[0m Trial 3 finished with value: 6.26882451185115 and parameters: {'max_depth': 8, 'learning_rate': 0.20066101752937415, 'n_estimators': 407}. Best is trial 3 with value: 6.26882451185115.\u001b[0m\n",
      "\u001b[32m[I 2023-05-24 03:41:39,561]\u001b[0m Trial 4 finished with value: 6.311834787072111 and parameters: {'max_depth': 8, 'learning_rate': 0.10898577442592079, 'n_estimators': 347}. Best is trial 3 with value: 6.26882451185115.\u001b[0m\n",
      "\u001b[32m[I 2023-05-24 03:41:56,140]\u001b[0m Trial 5 finished with value: 6.2811640082338265 and parameters: {'max_depth': 7, 'learning_rate': 0.27160421788355643, 'n_estimators': 645}. Best is trial 3 with value: 6.26882451185115.\u001b[0m\n",
      "\u001b[32m[I 2023-05-24 03:42:05,371]\u001b[0m Trial 6 finished with value: 6.322406635175562 and parameters: {'max_depth': 3, 'learning_rate': 0.14020093420147056, 'n_estimators': 481}. Best is trial 3 with value: 6.26882451185115.\u001b[0m\n",
      "\u001b[32m[I 2023-05-24 03:42:13,771]\u001b[0m Trial 7 finished with value: 6.26106734639302 and parameters: {'max_depth': 5, 'learning_rate': 0.1352943687379382, 'n_estimators': 310}. Best is trial 7 with value: 6.26106734639302.\u001b[0m\n",
      "\u001b[32m[I 2023-05-24 03:42:31,092]\u001b[0m Trial 8 finished with value: 6.286450956552461 and parameters: {'max_depth': 8, 'learning_rate': 0.17013782138012795, 'n_estimators': 573}. Best is trial 7 with value: 6.26106734639302.\u001b[0m\n",
      "\u001b[32m[I 2023-05-24 03:42:39,110]\u001b[0m Trial 9 finished with value: 6.272699589220561 and parameters: {'max_depth': 7, 'learning_rate': 0.07381709913072458, 'n_estimators': 209}. Best is trial 7 with value: 6.26106734639302.\u001b[0m\n",
      "\u001b[32m[I 2023-05-24 03:42:45,495]\u001b[0m Trial 10 finished with value: 6.312887322281998 and parameters: {'max_depth': 4, 'learning_rate': 0.05835222678326199, 'n_estimators': 250}. Best is trial 7 with value: 6.26106734639302.\u001b[0m\n",
      "\u001b[32m[I 2023-05-24 03:42:56,484]\u001b[0m Trial 11 finished with value: 6.302666158739219 and parameters: {'max_depth': 5, 'learning_rate': 0.21970136248947406, 'n_estimators': 458}. Best is trial 7 with value: 6.26106734639302.\u001b[0m\n",
      "\u001b[32m[I 2023-05-24 03:43:07,357]\u001b[0m Trial 12 finished with value: 6.258599985774779 and parameters: {'max_depth': 5, 'learning_rate': 0.20090997306562572, 'n_estimators': 442}. Best is trial 12 with value: 6.258599985774779.\u001b[0m\n",
      "\u001b[32m[I 2023-05-24 03:43:19,873]\u001b[0m Trial 13 finished with value: 6.282922776812685 and parameters: {'max_depth': 5, 'learning_rate': 0.13436926599864088, 'n_estimators': 515}. Best is trial 12 with value: 6.258599985774779.\u001b[0m\n",
      "\u001b[32m[I 2023-05-24 03:43:27,759]\u001b[0m Trial 14 finished with value: 6.280104005261225 and parameters: {'max_depth': 4, 'learning_rate': 0.22636150633689284, 'n_estimators': 295}. Best is trial 12 with value: 6.258599985774779.\u001b[0m\n",
      "\u001b[32m[I 2023-05-24 03:43:36,824]\u001b[0m Trial 15 finished with value: 6.272700315593109 and parameters: {'max_depth': 4, 'learning_rate': 0.19453739789795793, 'n_estimators': 410}. Best is trial 12 with value: 6.258599985774779.\u001b[0m\n",
      "\u001b[32m[I 2023-05-24 03:43:41,831]\u001b[0m Trial 16 finished with value: 6.271290027972809 and parameters: {'max_depth': 5, 'learning_rate': 0.15141536991504131, 'n_estimators': 148}. Best is trial 12 with value: 6.258599985774779.\u001b[0m\n",
      "\u001b[32m[I 2023-05-24 03:43:52,277]\u001b[0m Trial 17 finished with value: 6.325931762518336 and parameters: {'max_depth': 3, 'learning_rate': 0.11150543764737009, 'n_estimators': 539}. Best is trial 12 with value: 6.258599985774779.\u001b[0m\n",
      "\u001b[32m[I 2023-05-24 03:44:03,122]\u001b[0m Trial 18 finished with value: 6.3351021945403625 and parameters: {'max_depth': 6, 'learning_rate': 0.25007441604991293, 'n_estimators': 427}. Best is trial 12 with value: 6.258599985774779.\u001b[0m\n",
      "\u001b[32m[I 2023-05-24 03:44:10,326]\u001b[0m Trial 19 finished with value: 6.280106029310573 and parameters: {'max_depth': 4, 'learning_rate': 0.29835166927234436, 'n_estimators': 296}. Best is trial 12 with value: 6.258599985774779.\u001b[0m\n",
      "\u001b[32m[I 2023-05-24 03:44:24,639]\u001b[0m Trial 20 finished with value: 6.245909453887391 and parameters: {'max_depth': 5, 'learning_rate': 0.18539658586808733, 'n_estimators': 603}. Best is trial 20 with value: 6.245909453887391.\u001b[0m\n",
      "\u001b[32m[I 2023-05-24 03:44:37,979]\u001b[0m Trial 21 finished with value: 6.29138453518044 and parameters: {'max_depth': 5, 'learning_rate': 0.18982330841634298, 'n_estimators': 588}. Best is trial 20 with value: 6.245909453887391.\u001b[0m\n",
      "\u001b[32m[I 2023-05-24 03:44:52,452]\u001b[0m Trial 22 finished with value: 6.288564580213028 and parameters: {'max_depth': 5, 'learning_rate': 0.15771916563701452, 'n_estimators': 628}. Best is trial 20 with value: 6.245909453887391.\u001b[0m\n",
      "\u001b[32m[I 2023-05-24 03:45:04,997]\u001b[0m Trial 23 finished with value: 6.293852467102932 and parameters: {'max_depth': 6, 'learning_rate': 0.21563140948321782, 'n_estimators': 493}. Best is trial 20 with value: 6.245909453887391.\u001b[0m\n",
      "\u001b[32m[I 2023-05-24 03:45:13,732]\u001b[0m Trial 24 finished with value: 6.2748166651911035 and parameters: {'max_depth': 4, 'learning_rate': 0.17899874053914794, 'n_estimators': 365}. Best is trial 20 with value: 6.245909453887391.\u001b[0m\n",
      "\u001b[32m[I 2023-05-24 03:45:23,321]\u001b[0m Trial 25 finished with value: 6.279752096477156 and parameters: {'max_depth': 7, 'learning_rate': 0.20669857629434912, 'n_estimators': 301}. Best is trial 20 with value: 6.245909453887391.\u001b[0m\n",
      "\u001b[32m[I 2023-05-24 03:45:36,024]\u001b[0m Trial 26 finished with value: 6.285744045779876 and parameters: {'max_depth': 5, 'learning_rate': 0.23316127217623325, 'n_estimators': 554}. Best is trial 20 with value: 6.245909453887391.\u001b[0m\n",
      "\u001b[32m[I 2023-05-24 03:45:51,095]\u001b[0m Trial 27 finished with value: 6.286449389546515 and parameters: {'max_depth': 6, 'learning_rate': 0.18404176030390498, 'n_estimators': 595}. Best is trial 20 with value: 6.245909453887391.\u001b[0m\n",
      "\u001b[32m[I 2023-05-24 03:46:00,909]\u001b[0m Trial 28 finished with value: 6.256133816733977 and parameters: {'max_depth': 4, 'learning_rate': 0.2059604305598447, 'n_estimators': 442}. Best is trial 20 with value: 6.245909453887391.\u001b[0m\n",
      "\u001b[32m[I 2023-05-24 03:46:09,960]\u001b[0m Trial 29 finished with value: 6.268470211750716 and parameters: {'max_depth': 3, 'learning_rate': 0.23798162847574852, 'n_estimators': 461}. Best is trial 20 with value: 6.245909453887391.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "use_features = num_feat\n",
    "study_install = optuna.create_study(direction='minimize',study_name='install_log_loss')\n",
    "study_install.optimize(objective, n_trials=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eafec4d3-aaee-4b62-b2cf-5a8d5a31d4d6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-27 22:40:38,784]\u001b[0m A new study created in memory with name: install_log_loss\u001b[0m\n",
      "\u001b[32m[I 2023-05-27 22:40:49,453]\u001b[0m Trial 0 finished with value: 6.391161668145922 and parameters: {'max_depth': 3, 'learning_rate': 0.09527659985945318, 'n_estimators': 297}. Best is trial 0 with value: 6.391161668145922.\u001b[0m\n",
      "\u001b[32m[I 2023-05-27 22:41:00,586]\u001b[0m Trial 1 finished with value: 6.522664016786587 and parameters: {'max_depth': 3, 'learning_rate': 0.08977111741299722, 'n_estimators': 349}. Best is trial 0 with value: 6.391161668145922.\u001b[0m\n",
      "\u001b[32m[I 2023-05-27 22:41:09,480]\u001b[0m Trial 2 finished with value: 6.573785178100373 and parameters: {'max_depth': 4, 'learning_rate': 0.15091973298191896, 'n_estimators': 120}. Best is trial 0 with value: 6.391161668145922.\u001b[0m\n",
      "\u001b[32m[I 2023-05-27 22:41:25,317]\u001b[0m Trial 3 finished with value: 6.949623560233651 and parameters: {'max_depth': 8, 'learning_rate': 0.1428115484562847, 'n_estimators': 305}. Best is trial 0 with value: 6.391161668145922.\u001b[0m\n",
      "\u001b[32m[I 2023-05-27 22:41:36,367]\u001b[0m Trial 4 finished with value: 6.915075835044906 and parameters: {'max_depth': 7, 'learning_rate': 0.2543001775882751, 'n_estimators': 170}. Best is trial 0 with value: 6.391161668145922.\u001b[0m\n",
      "\u001b[32m[I 2023-05-27 22:41:49,729]\u001b[0m Trial 5 finished with value: 7.197826395345515 and parameters: {'max_depth': 8, 'learning_rate': 0.2202826292735378, 'n_estimators': 241}. Best is trial 0 with value: 6.391161668145922.\u001b[0m\n",
      "\u001b[32m[I 2023-05-27 22:42:03,062]\u001b[0m Trial 6 finished with value: 6.551946846000801 and parameters: {'max_depth': 3, 'learning_rate': 0.2149649332295674, 'n_estimators': 457}. Best is trial 0 with value: 6.391161668145922.\u001b[0m\n",
      "\u001b[32m[I 2023-05-27 22:42:18,511]\u001b[0m Trial 7 finished with value: 6.705645964716548 and parameters: {'max_depth': 7, 'learning_rate': 0.05060474840368474, 'n_estimators': 318}. Best is trial 0 with value: 6.391161668145922.\u001b[0m\n",
      "\u001b[32m[I 2023-05-27 22:42:31,681]\u001b[0m Trial 8 finished with value: 7.076195880494184 and parameters: {'max_depth': 7, 'learning_rate': 0.16112096273101228, 'n_estimators': 266}. Best is trial 0 with value: 6.391161668145922.\u001b[0m\n",
      "\u001b[32m[I 2023-05-27 22:42:41,750]\u001b[0m Trial 9 finished with value: 7.185119622094411 and parameters: {'max_depth': 8, 'learning_rate': 0.14892553185419777, 'n_estimators': 124}. Best is trial 0 with value: 6.391161668145922.\u001b[0m\n",
      "\u001b[32m[I 2023-05-27 22:42:59,738]\u001b[0m Trial 10 finished with value: 7.340261184698324 and parameters: {'max_depth': 5, 'learning_rate': 0.2948310781569337, 'n_estimators': 648}. Best is trial 0 with value: 6.391161668145922.\u001b[0m\n",
      "\u001b[32m[I 2023-05-27 22:43:12,382]\u001b[0m Trial 11 finished with value: 6.3989211922744635 and parameters: {'max_depth': 3, 'learning_rate': 0.09586509203596824, 'n_estimators': 445}. Best is trial 0 with value: 6.391161668145922.\u001b[0m\n",
      "\u001b[32m[I 2023-05-27 22:43:27,000]\u001b[0m Trial 12 finished with value: 6.873470583283645 and parameters: {'max_depth': 4, 'learning_rate': 0.10294483597524853, 'n_estimators': 461}. Best is trial 0 with value: 6.391161668145922.\u001b[0m\n",
      "\u001b[32m[I 2023-05-27 22:43:41,303]\u001b[0m Trial 13 finished with value: 7.009559204848187 and parameters: {'max_depth': 4, 'learning_rate': 0.11121414460006473, 'n_estimators': 447}. Best is trial 0 with value: 6.391161668145922.\u001b[0m\n",
      "\u001b[32m[I 2023-05-27 22:43:55,793]\u001b[0m Trial 14 finished with value: 6.4807130344886605 and parameters: {'max_depth': 3, 'learning_rate': 0.060372363722763195, 'n_estimators': 573}. Best is trial 0 with value: 6.391161668145922.\u001b[0m\n",
      "\u001b[32m[I 2023-05-27 22:44:10,284]\u001b[0m Trial 15 finished with value: 6.820952666098828 and parameters: {'max_depth': 5, 'learning_rate': 0.11433249985854982, 'n_estimators': 403}. Best is trial 0 with value: 6.391161668145922.\u001b[0m\n",
      "\u001b[32m[I 2023-05-27 22:44:25,561]\u001b[0m Trial 16 finished with value: 6.408454902035159 and parameters: {'max_depth': 4, 'learning_rate': 0.07661431394069716, 'n_estimators': 536}. Best is trial 0 with value: 6.391161668145922.\u001b[0m\n",
      "\u001b[32m[I 2023-05-27 22:44:37,645]\u001b[0m Trial 17 finished with value: 6.382359051650621 and parameters: {'max_depth': 6, 'learning_rate': 0.12417827974844235, 'n_estimators': 204}. Best is trial 17 with value: 6.382359051650621.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "use_features = all_feat + TrainSplit.DATE\n",
    "study_install = optuna.create_study(direction='minimize',study_name='install_log_loss')\n",
    "study_install.optimize(objective, n_trials=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "67583f50-763c-404b-a46a-2b10ec7bb78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "test = pd.read_csv('../Data/test/000000000000.csv',sep='\\t')\n",
    "test['f_30'].fillna(X['f_30'].mode()[0],inplace=True)\n",
    "test['f_31'].fillna(X['f_31'].mode()[0],inplace=True)\n",
    "fmiss = \"f_43,f_51,f_58,f_59,f_64,f_65,f_66,f_67,f_68,f_69,f_70\".split(',')\n",
    "for f in fmiss:\n",
    "    test[f].fillna(X[f].mean(),inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a3e5aefc-394c-4b00-a8e7-f7d88a6f01b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_all_feat = {'max_depth': 7, 'learning_rate': 0.05198517520669243, 'n_estimators': 606,\n",
    "                   'tree_method':'gpu_hist','objective':'binary:logistic'}\n",
    "params_cat_feat = {'max_depth': 4, 'learning_rate': 0.2972844912008205, 'n_estimators': 257,\n",
    "                   'tree_method':'gpu_hist','objective':'binary:logistic'}\n",
    "params_num_feat = {'max_depth': 5, 'learning_rate': 0.18539658586808733, 'n_estimators': 603,\n",
    "                   'tree_method':'gpu_hist','objective':'binary:logistic'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f9b73674-6b86-4147-bd43-da91d1a175b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.05198517520669243,\n",
       "              max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=7, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=606, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=None, ...)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_all_feat = XGBClassifier(**params_all_feat)\n",
    "model_all_feat.fit(X[all_feat],y[TrainSplit.IS_INSTALLED[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "38a183d8-4e05-49c6-8bfe-4d120a81218c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_install_pred = model_all_feat.predict_proba(X_train[all_feat])[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8fb8591e-bf95-44df-99a6-e05bb74bdd9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['xgb_pred'] = train_install_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "31ac28d5-e897-4f42-b0e4-36aa1bfe14a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test['xgb_pred'] = model_all_feat.predict_proba(X_test[all_feat])[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ff89fafc-c760-47f1-815b-bc7b29ab21bc",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0          0.068901\n",
       " 1          0.242679\n",
       " 2          0.279158\n",
       " 3          0.128261\n",
       " 4          0.028577\n",
       "              ...   \n",
       " 3485847    0.066495\n",
       " 3485848    0.027818\n",
       " 3485849    0.094219\n",
       " 3485850    0.363060\n",
       " 3485851    0.265923\n",
       " Name: xgb_pred, Length: 3387880, dtype: float32,\n",
       " 12         0.161562\n",
       " 20         0.302649\n",
       " 26         0.025512\n",
       " 83         0.074805\n",
       " 97         0.029013\n",
       "              ...   \n",
       " 3485578    0.068327\n",
       " 3485664    0.012814\n",
       " 3485724    0.068605\n",
       " 3485743    0.223019\n",
       " 3485807    0.144830\n",
       " Name: xgb_pred, Length: 97972, dtype: float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train['xgb_pred'],X_test['xgb_pred']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "da5f9578-27dc-428b-b2ce-4e8bfa2091b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.36431280693160106"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_loss(y_test[TrainSplit.IS_INSTALLED[0]],X_test['xgb_pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3b6f4083-181d-48d7-9a47-00db0767d036",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def objective(trail):\n",
    "    params = {  'C': trail.suggest_float('C',0,1),\n",
    "                # 'class_weight':'balanced',# Try None as well\n",
    "                'n_jobs': -1,\n",
    "                'max_iter':2000\n",
    "                # 'penalty': trail.suggest_categorical('penalty', [\"l1\", \"l2\", 'elasticnet']),\n",
    "             }\n",
    "    \n",
    "    target = TrainSplit.IS_INSTALLED[0]\n",
    "    model = LogisticRegression(**params)\n",
    "    model.fit(X_train['xgb_pred'].values.reshape(-1,1),y_train[TrainSplit.IS_INSTALLED[0]])\n",
    "    y_pred = model.predict_proba(X_test['xgb_pred'].values.reshape(-1,1))[:,1]\n",
    "    score = log_loss(y_test[target],y_pred)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d1475f0d-f560-4d69-a8cd-8983dabdd42f",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-26 13:33:31,218]\u001b[0m A new study created in memory with name: logistic_loss\u001b[0m\n",
      "\u001b[32m[I 2023-05-26 13:33:38,473]\u001b[0m Trial 0 finished with value: 0.377999565475483 and parameters: {'C': 0.16709935427365574}. Best is trial 0 with value: 0.377999565475483.\u001b[0m\n",
      "\u001b[32m[I 2023-05-26 13:33:44,049]\u001b[0m Trial 1 finished with value: 0.3779124085244122 and parameters: {'C': 0.033590909866925145}. Best is trial 1 with value: 0.3779124085244122.\u001b[0m\n",
      "\u001b[32m[I 2023-05-26 13:33:49,691]\u001b[0m Trial 2 finished with value: 0.3780174714463015 and parameters: {'C': 0.8530093830857242}. Best is trial 1 with value: 0.3779124085244122.\u001b[0m\n",
      "\u001b[32m[I 2023-05-26 13:33:55,224]\u001b[0m Trial 3 finished with value: 0.3780170242136945 and parameters: {'C': 0.7738685382490619}. Best is trial 1 with value: 0.3779124085244122.\u001b[0m\n",
      "\u001b[32m[I 2023-05-26 13:34:00,823]\u001b[0m Trial 4 finished with value: 0.3777659152655981 and parameters: {'C': 0.014049413490660911}. Best is trial 4 with value: 0.3777659152655981.\u001b[0m\n",
      "\u001b[32m[I 2023-05-26 13:34:06,367]\u001b[0m Trial 5 finished with value: 0.37801383674024214 and parameters: {'C': 0.465740413646042}. Best is trial 4 with value: 0.3777659152655981.\u001b[0m\n",
      "\u001b[32m[I 2023-05-26 13:34:11,893]\u001b[0m Trial 6 finished with value: 0.37801810391567564 and parameters: {'C': 0.997206707107365}. Best is trial 4 with value: 0.3777659152655981.\u001b[0m\n",
      "\u001b[33m[W 2023-05-26 13:34:14,937]\u001b[0m Trial 7 failed with parameters: {'C': 0.1241222647453375} because of the following error: KeyboardInterrupt().\u001b[0m\n",
      "Traceback (most recent call last):\n",
      "  File \"/home2/sisodiya.bhoomendra/venvs/python3.9_global/lib/python3.9/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_19833/2254883700.py\", line 13, in objective\n",
      "    model.fit(X_train['xgb_pred'].values.reshape(-1,1),y_train[TrainSplit.IS_INSTALLED[0]])\n",
      "  File \"/home2/sisodiya.bhoomendra/venvs/python3.9_global/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1406, in fit\n",
      "    fold_coefs_ = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/home2/sisodiya.bhoomendra/venvs/python3.9_global/lib/python3.9/site-packages/joblib/parallel.py\", line 1098, in __call__\n",
      "    self.retrieve()\n",
      "  File \"/home2/sisodiya.bhoomendra/venvs/python3.9_global/lib/python3.9/site-packages/joblib/parallel.py\", line 975, in retrieve\n",
      "    self._output.extend(job.get(timeout=self.timeout))\n",
      "  File \"/home2/sisodiya.bhoomendra/venvs/python3.9_global/lib/python3.9/site-packages/joblib/_parallel_backends.py\", line 567, in wrap_future_result\n",
      "    return future.result(timeout=timeout)\n",
      "  File \"/home2/sisodiya.bhoomendra/localpython/python3.9.16/lib/python3.9/concurrent/futures/_base.py\", line 441, in result\n",
      "    self._condition.wait(timeout)\n",
      "  File \"/home2/sisodiya.bhoomendra/localpython/python3.9.16/lib/python3.9/threading.py\", line 312, in wait\n",
      "    waiter.acquire()\n",
      "KeyboardInterrupt\n",
      "\u001b[33m[W 2023-05-26 13:34:14,939]\u001b[0m Trial 7 failed with value None.\u001b[0m\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m study_install \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mminimize\u001b[39m\u001b[38;5;124m'\u001b[39m,study_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlogistic_loss\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m \u001b[43mstudy_install\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/venvs/python3.9_global/lib/python3.9/site-packages/optuna/study/study.py:425\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    321\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    323\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    330\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    331\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    332\u001b[0m     \u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    333\u001b[0m \n\u001b[1;32m    334\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    422\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    423\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 425\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    426\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    427\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    428\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    429\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    430\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    431\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    432\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    433\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    434\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    435\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/venvs/python3.9_global/lib/python3.9/site-packages/optuna/study/_optimize.py:66\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 66\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     79\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/venvs/python3.9_global/lib/python3.9/site-packages/optuna/study/_optimize.py:163\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 163\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[1;32m    167\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    168\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[0;32m~/venvs/python3.9_global/lib/python3.9/site-packages/optuna/study/_optimize.py:251\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    246\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    247\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[1;32m    248\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    250\u001b[0m ):\n\u001b[0;32m--> 251\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[1;32m    252\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[0;32m~/venvs/python3.9_global/lib/python3.9/site-packages/optuna/study/_optimize.py:200\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[1;32m    199\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 200\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    201\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    202\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    203\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "Cell \u001b[0;32mIn[32], line 13\u001b[0m, in \u001b[0;36mobjective\u001b[0;34m(trail)\u001b[0m\n\u001b[1;32m     11\u001b[0m target \u001b[38;5;241m=\u001b[39m TrainSplit\u001b[38;5;241m.\u001b[39mIS_INSTALLED[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     12\u001b[0m model \u001b[38;5;241m=\u001b[39m LogisticRegression(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[0;32m---> 13\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mxgb_pred\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m[\u001b[49m\u001b[43mTrainSplit\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mIS_INSTALLED\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict_proba(X_test[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mxgb_pred\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m))[:,\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     15\u001b[0m score \u001b[38;5;241m=\u001b[39m log_loss(y_test[target],y_pred)\n",
      "File \u001b[0;32m~/venvs/python3.9_global/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1406\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1404\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1405\u001b[0m     prefer \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprocesses\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m-> 1406\u001b[0m fold_coefs_ \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1407\u001b[0m \u001b[43m                       \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m_joblib_parallel_args\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprefer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprefer\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1408\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mC_\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1409\u001b[0m \u001b[43m              \u001b[49m\u001b[43ml1_ratio\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43ml1_ratio\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfit_intercept\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_intercept\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1410\u001b[0m \u001b[43m              \u001b[49m\u001b[43mtol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msolver\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msolver\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1411\u001b[0m \u001b[43m              \u001b[49m\u001b[43mmulti_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmulti_class\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1412\u001b[0m \u001b[43m              \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1413\u001b[0m \u001b[43m              \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcoef\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwarm_start_coef_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1414\u001b[0m \u001b[43m              \u001b[49m\u001b[43mpenalty\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpenalty\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_squared_sum\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_squared_sum\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1415\u001b[0m \u001b[43m              \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1416\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mclass_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwarm_start_coef_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mclasses_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwarm_start_coef\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1418\u001b[0m fold_coefs_, _, n_iter_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mfold_coefs_)\n\u001b[1;32m   1419\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_iter_ \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(n_iter_, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mint32)[:, \u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/venvs/python3.9_global/lib/python3.9/site-packages/joblib/parallel.py:1098\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1095\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   1097\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1098\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1099\u001b[0m \u001b[38;5;66;03m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m elapsed_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_start_time\n",
      "File \u001b[0;32m~/venvs/python3.9_global/lib/python3.9/site-packages/joblib/parallel.py:975\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    973\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    974\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msupports_timeout\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m--> 975\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(\u001b[43mjob\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    976\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    977\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(job\u001b[38;5;241m.\u001b[39mget())\n",
      "File \u001b[0;32m~/venvs/python3.9_global/lib/python3.9/site-packages/joblib/_parallel_backends.py:567\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    564\u001b[0m \u001b[38;5;124;03m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[1;32m    565\u001b[0m \u001b[38;5;124;03mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[1;32m    566\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 567\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    568\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m CfTimeoutError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    569\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[0;32m~/localpython/python3.9.16/lib/python3.9/concurrent/futures/_base.py:441\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[1;32m    439\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_result()\n\u001b[0;32m--> 441\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_condition\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    443\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[1;32m    444\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[0;32m~/localpython/python3.9.16/lib/python3.9/threading.py:312\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    311\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 312\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    313\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    314\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "study_install = optuna.create_study(direction='minimize',study_name='logistic_loss')\n",
    "study_install.optimize(objective, n_trials=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "79cb6fb3-5b7f-4bac-9d4f-22d15ff76d0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.4436042554891082, max_iter=2000, n_jobs=-1)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {  'C': 0.4436042554891082,\n",
    "            'n_jobs': -1,\n",
    "            'max_iter':2000}\n",
    "\n",
    "model = LogisticRegression(**params)\n",
    "model.fit(X_test['xgb_pred'].values.reshape(-1,1),y_test[TrainSplit.IS_INSTALLED[0]])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6e270008-fbcf-400b-85cd-182208c040a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_proba = model_all_feat.predict_proba(test[all_feat])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d6dca756-fb3b-4d79-8d7b-e51e58d642c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "calib_proba = model.predict_proba(xgb_proba[:,1].reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ea7a74d4-8503-45d8-8263-76b4ddd4228a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved the test result to csv file as xgb_full_data_2023-05-27 22:29:12.147504.csv\n",
      "Saved the model config to json file as xgb_full_data_2023-05-27 22:29:12.147504.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<utils.TestResults at 0x14f34fdb6490>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TestResults(row_id=test['f_0'],is_click=np.random.random(xgb_proba[:,1].shape[0]),\n",
    "            is_install=xgb_proba[:,1],model_name=\"xgb_full_data\",config=params_all_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "95ec22ba-e870-4e43-882b-d4809e912713",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03103035533591397"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.abs(calib_proba[:,1]-xgb_proba[:,1]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aca688d7-4a3b-4b4e-b4f6-9979fef42965",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trail):\n",
    "    params = {\n",
    "        'max_depth':trail.suggest_int('max_depth',3,5),\n",
    "        'learning_rate':trail.suggest_float('learning_rate',0.05,0.5),\n",
    "        'n_estimators':trail.suggest_int('n_estimators',4,50),\n",
    "        'tree_method':'gpu_hist',\n",
    "        'objective':'binary:logistic'\n",
    "    }\n",
    "    # print(use_features)\n",
    "    target = TrainSplit.IS_INSTALLED[0]\n",
    "    model = XGBClassifier(**params)\n",
    "    model.fit(X_train[use_features],y_train[target])\n",
    "    y_pred = model.predict(X_test[use_features])\n",
    "    score = log_loss(y_test[target],y_pred)\n",
    "    # print(model.feature_names_in_)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1ea1a62a-7754-4f6a-b726-f43a495a3a5e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-25 14:41:13,397]\u001b[0m A new study created in memory with name: install_log_loss\u001b[0m\n",
      "\u001b[32m[I 2023-05-25 14:41:21,042]\u001b[0m Trial 0 finished with value: 6.127142998691673 and parameters: {'max_depth': 5, 'learning_rate': 0.30359859436425907, 'n_estimators': 43}. Best is trial 0 with value: 6.127142998691673.\u001b[0m\n",
      "\u001b[32m[I 2023-05-25 14:41:28,169]\u001b[0m Trial 1 finished with value: 6.026658302034461 and parameters: {'max_depth': 4, 'learning_rate': 0.12269114208826071, 'n_estimators': 26}. Best is trial 1 with value: 6.026658302034461.\u001b[0m\n",
      "\u001b[32m[I 2023-05-25 14:41:35,606]\u001b[0m Trial 2 finished with value: 6.031946058340535 and parameters: {'max_depth': 4, 'learning_rate': 0.12097888238229475, 'n_estimators': 32}. Best is trial 1 with value: 6.026658302034461.\u001b[0m\n",
      "\u001b[32m[I 2023-05-25 14:41:42,397]\u001b[0m Trial 3 finished with value: 6.085183128531894 and parameters: {'max_depth': 3, 'learning_rate': 0.368858419347425, 'n_estimators': 28}. Best is trial 1 with value: 6.026658302034461.\u001b[0m\n",
      "\u001b[32m[I 2023-05-25 14:41:48,707]\u001b[0m Trial 4 finished with value: 5.992102619393643 and parameters: {'max_depth': 3, 'learning_rate': 0.4900509143647155, 'n_estimators': 8}. Best is trial 4 with value: 5.992102619393643.\u001b[0m\n",
      "\u001b[32m[I 2023-05-25 14:41:55,605]\u001b[0m Trial 5 finished with value: 6.031946058340535 and parameters: {'max_depth': 5, 'learning_rate': 0.09764183660793713, 'n_estimators': 17}. Best is trial 4 with value: 5.992102619393643.\u001b[0m\n",
      "\u001b[32m[I 2023-05-25 14:42:02,546]\u001b[0m Trial 6 finished with value: 6.023835221216645 and parameters: {'max_depth': 3, 'learning_rate': 0.18695951368561714, 'n_estimators': 31}. Best is trial 4 with value: 5.992102619393643.\u001b[0m\n",
      "\u001b[32m[I 2023-05-25 14:42:09,177]\u001b[0m Trial 7 finished with value: 6.05803739542149 and parameters: {'max_depth': 3, 'learning_rate': 0.050500960903689746, 'n_estimators': 14}. Best is trial 4 with value: 5.992102619393643.\u001b[0m\n",
      "\u001b[32m[I 2023-05-25 14:42:16,083]\u001b[0m Trial 8 finished with value: 6.0389971699824585 and parameters: {'max_depth': 3, 'learning_rate': 0.2662266275573377, 'n_estimators': 22}. Best is trial 4 with value: 5.992102619393643.\u001b[0m\n",
      "\u001b[32m[I 2023-05-25 14:42:23,504]\u001b[0m Trial 9 finished with value: 6.030183804805741 and parameters: {'max_depth': 5, 'learning_rate': 0.18354152746450697, 'n_estimators': 15}. Best is trial 4 with value: 5.992102619393643.\u001b[0m\n",
      "\u001b[32m[I 2023-05-25 14:42:30,960]\u001b[0m Trial 10 finished with value: 6.026658302034461 and parameters: {'max_depth': 4, 'learning_rate': 0.4924212619449354, 'n_estimators': 6}. Best is trial 4 with value: 5.992102619393643.\u001b[0m\n",
      "\u001b[32m[I 2023-05-25 14:42:38,753]\u001b[0m Trial 11 finished with value: 6.144413747677875 and parameters: {'max_depth': 3, 'learning_rate': 0.4815242419721575, 'n_estimators': 39}. Best is trial 4 with value: 5.992102619393643.\u001b[0m\n",
      "\u001b[32m[I 2023-05-25 14:42:45,954]\u001b[0m Trial 12 finished with value: 6.121498257155182 and parameters: {'max_depth': 3, 'learning_rate': 0.4020338415795476, 'n_estimators': 50}. Best is trial 4 with value: 5.992102619393643.\u001b[0m\n",
      "\u001b[32m[I 2023-05-25 14:42:52,196]\u001b[0m Trial 13 finished with value: 6.026658302034461 and parameters: {'max_depth': 3, 'learning_rate': 0.21491985589925142, 'n_estimators': 6}. Best is trial 4 with value: 5.992102619393643.\u001b[0m\n",
      "\u001b[32m[I 2023-05-25 14:42:59,502]\u001b[0m Trial 14 finished with value: 6.09576021631148 and parameters: {'max_depth': 4, 'learning_rate': 0.31759101687475055, 'n_estimators': 34}. Best is trial 4 with value: 5.992102619393643.\u001b[0m\n",
      "\u001b[32m[I 2023-05-25 14:43:06,291]\u001b[0m Trial 15 finished with value: 6.03300333537571 and parameters: {'max_depth': 3, 'learning_rate': 0.22400436938487372, 'n_estimators': 21}. Best is trial 4 with value: 5.992102619393643.\u001b[0m\n",
      "\u001b[32m[I 2023-05-25 14:43:12,876]\u001b[0m Trial 16 finished with value: 6.036176553934413 and parameters: {'max_depth': 4, 'learning_rate': 0.38179129959855085, 'n_estimators': 10}. Best is trial 4 with value: 5.992102619393643.\u001b[0m\n",
      "\u001b[32m[I 2023-05-25 14:43:20,039]\u001b[0m Trial 17 finished with value: 6.1296080577699295 and parameters: {'max_depth': 3, 'learning_rate': 0.4458225962089233, 'n_estimators': 36}. Best is trial 4 with value: 5.992102619393643.\u001b[0m\n",
      "\u001b[32m[I 2023-05-25 14:43:27,517]\u001b[0m Trial 18 finished with value: 6.111626390719894 and parameters: {'max_depth': 4, 'learning_rate': 0.3371520458527128, 'n_estimators': 28}. Best is trial 4 with value: 5.992102619393643.\u001b[0m\n",
      "\u001b[32m[I 2023-05-25 14:43:35,775]\u001b[0m Trial 19 finished with value: 6.132427506725004 and parameters: {'max_depth': 3, 'learning_rate': 0.4428183071937891, 'n_estimators': 42}. Best is trial 4 with value: 5.992102619393643.\u001b[0m\n",
      "\u001b[32m[I 2023-05-25 14:43:43,383]\u001b[0m Trial 20 finished with value: 6.044991037235166 and parameters: {'max_depth': 4, 'learning_rate': 0.24534175547355913, 'n_estimators': 22}. Best is trial 4 with value: 5.992102619393643.\u001b[0m\n",
      "\u001b[32m[I 2023-05-25 14:43:50,671]\u001b[0m Trial 21 finished with value: 6.0330042331395335 and parameters: {'max_depth': 4, 'learning_rate': 0.17075476129988854, 'n_estimators': 25}. Best is trial 4 with value: 5.992102619393643.\u001b[0m\n",
      "\u001b[32m[I 2023-05-25 14:43:57,507]\u001b[0m Trial 22 finished with value: 6.077426934290989 and parameters: {'max_depth': 3, 'learning_rate': 0.2674339725828597, 'n_estimators': 32}. Best is trial 4 with value: 5.992102619393643.\u001b[0m\n",
      "\u001b[32m[I 2023-05-25 14:44:04,130]\u001b[0m Trial 23 finished with value: 6.026658302034461 and parameters: {'max_depth': 4, 'learning_rate': 0.16000518839659195, 'n_estimators': 11}. Best is trial 4 with value: 5.992102619393643.\u001b[0m\n",
      "\u001b[32m[I 2023-05-25 14:44:12,043]\u001b[0m Trial 24 finished with value: 6.112332313952273 and parameters: {'max_depth': 5, 'learning_rate': 0.1987129331322655, 'n_estimators': 50}. Best is trial 4 with value: 5.992102619393643.\u001b[0m\n",
      "\u001b[32m[I 2023-05-25 14:44:18,764]\u001b[0m Trial 25 finished with value: 5.992102619393643 and parameters: {'max_depth': 3, 'learning_rate': 0.14021097785457837, 'n_estimators': 18}. Best is trial 4 with value: 5.992102619393643.\u001b[0m\n",
      "\u001b[32m[I 2023-05-25 14:44:25,065]\u001b[0m Trial 26 finished with value: 6.0985855905077875 and parameters: {'max_depth': 3, 'learning_rate': 0.291709275973123, 'n_estimators': 4}. Best is trial 4 with value: 5.992102619393643.\u001b[0m\n",
      "\u001b[32m[I 2023-05-25 14:44:31,730]\u001b[0m Trial 27 finished with value: 6.021718643096949 and parameters: {'max_depth': 3, 'learning_rate': 0.2385031214509522, 'n_estimators': 18}. Best is trial 4 with value: 5.992102619393643.\u001b[0m\n",
      "\u001b[32m[I 2023-05-25 14:44:38,430]\u001b[0m Trial 28 finished with value: 6.031946058340535 and parameters: {'max_depth': 3, 'learning_rate': 0.24261233590800205, 'n_estimators': 19}. Best is trial 4 with value: 5.992102619393643.\u001b[0m\n",
      "\u001b[32m[I 2023-05-25 14:44:45,345]\u001b[0m Trial 29 finished with value: 5.992102619393643 and parameters: {'max_depth': 3, 'learning_rate': 0.32023238908217044, 'n_estimators': 11}. Best is trial 4 with value: 5.992102619393643.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "use_features = all_feat+['xgb_pred']\n",
    "study_install = optuna.create_study(direction='minimize',study_name='install_log_loss')\n",
    "study_install.optimize(objective, n_trials=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9d14ea6d-f138-4d26-9fae-29b984104f0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.4900509143647155,\n",
       "              max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=3, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=8, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=None, ...)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "level2xgb_params = {'max_depth': 3, 'learning_rate': 0.4900509143647155, 'n_estimators': 8,'tree_method':'gpu_hist',\n",
    "                    'objective':'binary:logistic'}\n",
    "target = TrainSplit.IS_INSTALLED[0]\n",
    "model = XGBClassifier(**level2xgb_params)\n",
    "model.fit(X_train[use_features],y_train[target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1dce84c1-8f9e-429a-bd75-c51536be4357",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "test = pd.read_csv('../Data/test/000000000000.csv',sep='\\t')\n",
    "test['f_30'].fillna(X['f_30'].mode()[0],inplace=True)\n",
    "test['f_31'].fillna(X['f_31'].mode()[0],inplace=True)\n",
    "fmiss = \"f_43,f_51,f_58,f_59,f_64,f_65,f_66,f_67,f_68,f_69,f_70\".split(',')\n",
    "for f in fmiss:\n",
    "    test[f].fillna(X[f].mean(),inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "435a653e-c773-4ad2-80e2-9fd58ec29df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test['xgb_pred'] = model_all_feat.predict_proba(test[all_feat])[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "949772ea-7aa2-416c-8b66-48ecad13ecf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "install_pred_all = model.predict_proba(test[use_features])[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "440c9492-7a5d-4854-93a7-1f9d73ed7e28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.20049362, 0.3117722 , 0.07335331, ..., 0.01842373, 0.11533546,\n",
       "       0.05473805], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "install_pred_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ceb8b449-e776-4724-ad48-adbbb09f60dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01064414"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(np.abs(install_pred_all - test['xgb_pred']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "79ef6413-0239-4317-9615-d18d72b579f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_all_feat.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "735a45f9-a019-4cab-b461-0fee07ba841f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((160973,), (160973, 81))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "install_pred_all.shape,test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9518d30b-2661-499c-8094-5edfd09c537e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TestResults(row_id=test['f_0'],is_click=np.random.random(install_pred_all.shape[0]),\n",
    "#             is_install=install_pred_all,model_name=\"xgb_all_feat_xgb_chain\",config=params_all_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b6d5d925-358b-4220-b657-0d44a8efe14b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.2972844912008205,\n",
       "              max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=4, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=257, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=None, ...)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_cat_feat = XGBClassifier(**params_cat_feat)\n",
    "model_cat_feat.fit(X_train[cat_feat],y_train[TrainSplit.IS_INSTALLED[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9574a067-8b57-4167-a95d-00cb1eccbcfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "install_pred_cat = model_cat_feat.predict_proba(test[cat_feat])[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b644759e-d68a-4e59-a5f1-31429657a90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TestResults(row_id=test['f_0'],is_click=np.random.random(install_pred_cat.shape[0]),\n",
    "#             is_install=install_pred_cat,model_name=\"xgb_cat_feat\",config=params_all_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cced6462-e71f-4f72-a9bc-aaffea4eb817",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.18539658586808733,\n",
       "              max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=5, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=603, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=None, ...)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_num_feat = XGBClassifier(**params_num_feat)\n",
    "model_num_feat.fit(X_train[num_feat],y_train[TrainSplit.IS_INSTALLED[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cfb05111-4fd6-4f7a-95aa-ce4ca0275aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "install_pred_num = model_num_feat.predict_proba(test[num_feat])[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6cb6b4bd-ad51-4fa9-a23e-5be570382587",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TestResults(row_id=test['f_0'],is_click=np.random.random(install_pred_num.shape[0]),\n",
    "#             is_install=install_pred_num,model_name=\"xgb_num_feat\",config=params_all_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bc8d95ab-17fb-4048-835a-9abc547dab10",
   "metadata": {},
   "outputs": [],
   "source": [
    "install_avg = (install_pred_cat + install_pred_num + test['xgb_pred'])/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d7b54e56-3138-4fb4-8e76-2461f4f34183",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved the test result to csv file as xgb_num_cat_all_avg_2023-05-25 16:21:55.184468.csv\n",
      "Saved the model config to json file as xgb_num_cat_all_avg_2023-05-25 16:21:55.184468.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<utils.TestResults at 0x14b7c284d0a0>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TestResults(row_id=test['f_0'],is_click=np.random.random(install_avg.shape[0]),\n",
    "            is_install=install_avg,model_name=\"xgb_num_cat_all_avg\",config=params_all_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bbf1ac81-ae24-45b5-bb1f-9c82ae0f7bb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['catboost_all_feat_2023-05-25 11:41:56.839795.json',\n",
       " 'xgb_stack_all_cat_num_2023-05-25 04:08:18.733781.json',\n",
       " 'xgb_cat_feat_2023-05-24 05:09:00.493398.json',\n",
       " 'xgb_num_feat_2023-05-24 05:09:31.486438.json',\n",
       " 'xgb_stack_all_cat_num_xgb_2023-05-25 06:19:35.109117.json',\n",
       " 'xgb_num_cat_all_avg_2023-05-25 16:21:55.184468.json',\n",
       " 'xgb_all_feat_xgb_chain_2023-05-25 16:05:56.352515.json',\n",
       " 'xgb_all_feat_2023-05-24 05:08:29.718082.json']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TrainSplit.get_config_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a52b479e-8054-4065-a111-653abf3da939",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_pred = pd.read_csv('../Data/results/catboost_all_feat_2023-05-25 11:41:56.839795.csv',sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b0d931f1-4d35-456b-89f3-ba8d18aff608",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_pred = pd.read_csv('../Data/results/xgb_all_feat_2023-05-24 05:08:29.718082.csv',sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2f76b62b-386c-4a61-b376-b909b9d5011d",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = np.abs(cat_pred[TrainSplit.IS_INSTALLED[0]]-xgb_pred[TrainSplit.IS_INSTALLED[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "8a89920f-b095-4f09-94f6-7d63d3b735f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1114"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(out[out>0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69aa6421-8262-4933-bbfe-0e7bc9f798b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
